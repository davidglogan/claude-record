#!/bin/bash

# Claude Recording Wrapper Script
# Automatically records all Claude Code conversations with metadata and management features
#
# Author: Generated by Claude Code
# Version: 1.0
# 
# This script wraps the claude command to automatically record all interactions
# with timestamps, session metadata, and automatic log management.

set -euo pipefail

# Script configuration
SCRIPT_NAME="claude-record"
SCRIPT_VERSION="2.0-alpha"
DEFAULT_LOG_DIR="$HOME/Documents/claude"
DEFAULT_MAX_SIZE="100M"
DEFAULT_MAX_SESSIONS=50
CLAUDE_CMD="claude"

# v2.0 Configuration
AUTO_SUMMARIZE=true
SUMMARY_TIMEOUT=30
MIN_SESSION_LENGTH=60
MAX_LOG_SIZE_FOR_SUMMARY=$((10 * 1024 * 1024))  # 10MB in bytes
SUMMARIZE_ONLY=false
REBUILD_INDEX=false

# Phase 3: Context Retrieval
SHOW_CONTEXT=true
CONTEXT_MODE="smart"  # "recent", "smart", "keywords"
NUM_CONTEXT_SESSIONS=3
CONTEXT_KEYWORDS=""

# Color codes for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Global variables
LOG_DIR="$DEFAULT_LOG_DIR"
CUSTOM_FILENAME=""
MAX_SIZE="$DEFAULT_MAX_SIZE"
MAX_SESSIONS="$DEFAULT_MAX_SESSIONS"
VERBOSE=false
DRY_RUN=false
CLEANUP_ONLY=false
LIST_SESSIONS=false
SEARCH_TERM=""
AUTO_CLEANUP=true

# Platform detection
detect_platform() {
    case "$(uname -s)" in
        Darwin*)    echo "macos" ;;
        Linux*)     echo "linux" ;;
        CYGWIN*|MINGW*|MSYS*) echo "windows" ;;
        *)          echo "unknown" ;;
    esac
}

PLATFORM=$(detect_platform)

# Cross-platform date to epoch conversion
# Converts ISO8601 date to Unix epoch timestamp
date_to_epoch() {
    local iso_date="$1"

    # Extract just the date/time part (first 19 chars: YYYY-MM-DDTHH:MM:SS)
    local clean_date="${iso_date:0:19}"

    case "$PLATFORM" in
        macos)
            # BSD date (macOS)
            date -j -f "%Y-%m-%dT%H:%M:%S" "$clean_date" "+%s" 2>/dev/null || echo "0"
            ;;
        linux)
            # GNU date (Linux)
            date -d "$clean_date" "+%s" 2>/dev/null || echo "0"
            ;;
        windows)
            # Git Bash on Windows should have GNU date
            date -d "$clean_date" "+%s" 2>/dev/null || echo "0"
            ;;
        *)
            echo "0"
            ;;
    esac
}

# Utility functions
log_info() {
    echo -e "${CYAN}[INFO]${NC} $1" >&2
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1" >&2
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1" >&2
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1" >&2
}

verbose_log() {
    if [[ "$VERBOSE" == "true" ]]; then
        echo -e "${PURPLE}[VERBOSE]${NC} $1" >&2
    fi
}

# Convert human readable sizes to bytes
size_to_bytes() {
    local size="$1"
    local num="${size%[KMGT]*}"
    local unit="${size#$num}"
    
    case "${unit^^}" in
        K|KB) echo $((num * 1024)) ;;
        M|MB) echo $((num * 1024 * 1024)) ;;
        G|GB) echo $((num * 1024 * 1024 * 1024)) ;;
        T|TB) echo $((num * 1024 * 1024 * 1024 * 1024)) ;;
        *) echo "$num" ;;
    esac
}

# Format bytes to human readable
bytes_to_size() {
    local bytes="$1"
    if (( bytes > 1073741824 )); then
        printf "%.1fG" $((bytes / 1073741824))
    elif (( bytes > 1048576 )); then
        printf "%.1fM" $((bytes / 1048576))
    elif (( bytes > 1024 )); then
        printf "%.1fK" $((bytes / 1024))
    else
        printf "%dB" "$bytes"
    fi
}

# Display help
show_help() {
    cat << EOF
$SCRIPT_NAME v$SCRIPT_VERSION - Claude Code Session Recording Wrapper

USAGE:
    $SCRIPT_NAME [OPTIONS] [CLAUDE_ARGS...]

DESCRIPTION:
    Automatically records Claude Code conversations with timestamps, metadata,
    and intelligent log management. All Claude arguments are passed through.

OPTIONS:
    -h, --help              Show this help message
    -d, --directory DIR     Recording directory (default: $DEFAULT_LOG_DIR)
    -f, --filename NAME     Custom filename prefix (default: claude_conversation)
    -s, --max-size SIZE     Maximum log file size before rotation (default: $DEFAULT_MAX_SIZE)
    -m, --max-sessions NUM  Maximum number of session files to keep (default: $DEFAULT_MAX_SESSIONS)
    -v, --verbose           Enable verbose output
    --dry-run              Show what would be done without executing
    --cleanup              Clean up old sessions and exit
    --list                 List all recorded sessions and exit
    --search TERM          Search through recorded sessions for TERM
    --no-auto-cleanup      Disable automatic cleanup of old sessions
    --no-summarize         Disable automatic summary generation (v2.0)
    --summarize-only       Generate summary for most recent session and exit (v2.0)
    --rebuild-index        Rebuild keyword and session indexes from summaries (v2.0)
    --no-context           Disable context retrieval at startup (v2.0)
    --context MODE         Context mode: recent, smart, keywords (default: smart) (v2.0)
    --context-keywords KW  Keywords for context search (space-separated) (v2.0)
    --version              Show version information

SIZE FORMAT:
    Sizes can be specified with suffixes: K/KB, M/MB, G/GB, T/TB
    Examples: 50M, 1G, 512K, 2048

EXAMPLES:
    # Basic usage - record a Claude session
    $SCRIPT_NAME

    # Custom directory and filename
    $SCRIPT_NAME -d ~/my-claude-logs -f my_session

    # Limit file size and keep more sessions
    $SCRIPT_NAME -s 50MB -m 100

    # Pass arguments to Claude
    $SCRIPT_NAME --model claude-3-sonnet

    # List all recorded sessions
    $SCRIPT_NAME --list

    # Search for specific content in sessions
    $SCRIPT_NAME --search "performance test"

    # Clean up old sessions
    $SCRIPT_NAME --cleanup

FILES:
    Session files are saved as:
    \$LOG_DIR/claude_conversation.YYYYMMDD-HHMMSS.log

    Metadata files are saved as:
    \$LOG_DIR/claude_conversation.YYYYMMDD-HHMMSS.meta

FEATURES:
    â€¢ Automatic timestamping and session metadata
    â€¢ File size monitoring with automatic rotation
    â€¢ Intelligent cleanup of old sessions
    â€¢ Search functionality across all sessions
    â€¢ Session listing with metadata
    â€¢ Progress indicators for long sessions
    â€¢ Error handling and recovery
    â€¢ Support for all Claude Code arguments

ENVIRONMENT VARIABLES:
    CLAUDE_RECORD_DIR       Default recording directory
    CLAUDE_RECORD_MAX_SIZE  Default maximum file size
    CLAUDE_CMD              Claude command to execute (default: claude)

EOF
}

# Create log directory
setup_log_directory() {
    if [[ ! -d "$LOG_DIR" ]]; then
        verbose_log "Creating log directory: $LOG_DIR"
        if [[ "$DRY_RUN" == "false" ]]; then
            mkdir -p "$LOG_DIR" || {
                log_error "Failed to create log directory: $LOG_DIR"
                exit 1
            }
        fi
        log_success "Created log directory: $LOG_DIR"
    fi
    
    # Ensure we can write to the directory
    if [[ "$DRY_RUN" == "false" ]] && [[ ! -w "$LOG_DIR" ]]; then
        log_error "Cannot write to log directory: $LOG_DIR"
        exit 1
    fi
}

# Generate session filename
generate_filename() {
    local timestamp=$(date +%Y%m%d-%H%M%S)
    local prefix="${CUSTOM_FILENAME:-claude_conversation}"
    echo "${LOG_DIR}/${prefix}.${timestamp}.log"
}

# Generate metadata filename
generate_metadata_filename() {
    local log_file="$1"
    echo "${log_file%.log}.meta"
}

# Create session metadata
create_metadata() {
    local log_file="$1"
    local meta_file="$(generate_metadata_filename "$log_file")"
    local start_time="$2"
    
    verbose_log "Creating metadata file: $meta_file"
    
    if [[ "$DRY_RUN" == "false" ]]; then
        cat > "$meta_file" << EOF
# Claude Session Metadata
session_start="$start_time"
session_file="$(basename "$log_file")"
session_directory="$LOG_DIR"
claude_args="$*"
max_size="$MAX_SIZE"
hostname="$(hostname)"
user="$(whoami)"
pwd="$(pwd)"
script_version="$SCRIPT_VERSION"
EOF
    fi
}

# Update metadata on session end
update_metadata() {
    local log_file="$1"
    local meta_file="$(generate_metadata_filename "$log_file")"
    local end_time="$2"
    local file_size="$3"
    
    if [[ "$DRY_RUN" == "false" ]] && [[ -f "$meta_file" ]]; then
        {
            echo "session_end=\"$end_time\""
            echo "final_size=\"$file_size\""
            echo "duration_seconds=\"$(( $(date -d "$end_time" +%s) - $(date -d "$(grep session_start "$meta_file" | cut -d'"' -f2)" +%s) ))\""
        } >> "$meta_file"
    fi
}

# Check if file exceeds size limit
check_file_size() {
    local file="$1"
    local max_bytes=$(size_to_bytes "$MAX_SIZE")
    
    if [[ -f "$file" ]]; then
        local current_size=$(stat -f%z "$file" 2>/dev/null || stat -c%s "$file" 2>/dev/null || echo 0)
        if (( current_size > max_bytes )); then
            return 0  # File is too large
        fi
    fi
    return 1  # File is within limits
}

# Rotate log file if needed
rotate_log_if_needed() {
    local log_file="$1"
    
    if check_file_size "$log_file"; then
        local rotated_file="${log_file%.log}.$(date +%H%M%S).log"
        verbose_log "Rotating log file: $log_file -> $(basename "$rotated_file")"
        
        if [[ "$DRY_RUN" == "false" ]]; then
            mv "$log_file" "$rotated_file"
            # Update metadata for rotated file
            local meta_file="$(generate_metadata_filename "$log_file")"
            local rotated_meta="${rotated_file%.log}.meta"
            if [[ -f "$meta_file" ]]; then
                mv "$meta_file" "$rotated_meta"
                echo "rotated_at=\"$(date -Iseconds)\"" >> "$rotated_meta"
            fi
        fi
        
        log_info "Log file rotated due to size limit ($(bytes_to_size $(size_to_bytes "$MAX_SIZE")))"
        return 0  # File was rotated
    fi
    return 1  # No rotation needed
}

# Filter out repetitive Claude UI sequences
filter_claude_ui_sequences() {
    local input_file="$1"
    local output_file="$2"
    
    if [[ ! -f "$input_file" ]]; then
        log_error "Input file not found: $input_file"
        return 1
    fi
    
    verbose_log "Filtering Claude UI sequences to reduce log size"
    
    # Use sed and grep to filter out repetitive patterns
    # Remove ANSI escape sequences, repetitive cursor movements, and cooking animations
    sed -E '
        # Remove ANSI color codes and cursor control sequences
        s/\x1b\[[0-9;]*[mGKH]//g
        s/\x1b\[[0-9]*[ABCD]//g
        s/\x1b\[2K//g
        s/\x1b\[\?[0-9]+[hl]//g
        # Remove repetitive cursor positioning
        s/\x1b\[[0-9]+;[0-9]+H//g
        # Remove form feed and other control chars except newlines
        s/[\x0C\x0E\x0F]//g
    ' "$input_file" | \
    # Filter out lines that are mostly repetitive UI elements
    grep -v -E '(â•­â”€+â•®|â”‚.*â”‚|â•°â”€+â•¯)$' | \
    # Remove excessive blank lines (keep max 2 consecutive)
    awk '
        /^[[:space:]]*$/ { 
            blank++; 
            if (blank <= 2) print; 
            next 
        } 
        { blank=0; print }
    ' > "$output_file"
    
    local original_size=$(stat -c%s "$input_file" 2>/dev/null || echo 0)
    local filtered_size=$(stat -c%s "$output_file" 2>/dev/null || echo 0)
    local reduction=$((original_size - filtered_size))
    
    verbose_log "Log size reduced by $(bytes_to_size $reduction) ($(printf "%.1f" $(echo "scale=1; $reduction * 100 / $original_size" | bc 2>/dev/null || echo "0"))%)"
}

# Clean up old sessions
cleanup_old_sessions() {
    verbose_log "Cleaning up old sessions (keeping $MAX_SESSIONS most recent)"
    
    local session_files=()
    while IFS=  read -r -d $'\0' file; do
        session_files+=("$file")
    done < <(find "$LOG_DIR" -name "*.log" -print0 2>/dev/null | sort -z)
    
    local total_files=${#session_files[@]}
    verbose_log "Found $total_files session files"
    
    if (( total_files > MAX_SESSIONS )); then
        local files_to_remove=$((total_files - MAX_SESSIONS))
        log_info "Removing $files_to_remove old session files"
        
        for (( i=0; i<files_to_remove; i++ )); do
            local file="${session_files[i]}"
            local meta_file="$(generate_metadata_filename "$file")"
            
            verbose_log "Removing: $(basename "$file")"
            if [[ "$DRY_RUN" == "false" ]]; then
                rm -f "$file" "$meta_file"
            fi
        done
        
        log_success "Cleaned up $files_to_remove old session files"
    else
        verbose_log "No cleanup needed (have $total_files, limit $MAX_SESSIONS)"
    fi
}

# List all sessions
list_sessions() {
    log_info "Recorded Claude Sessions in $LOG_DIR:"
    echo
    
    local sessions=()
    while IFS=  read -r -d $'\0' file; do
        sessions+=("$file")
    done < <(find "$LOG_DIR" -name "*.log" -print0 2>/dev/null | sort -z -r)
    
    if [[ ${#sessions[@]} -eq 0 ]]; then
        echo "No recorded sessions found."
        return
    fi
    
    printf "%-20s %-12s %-8s %-20s %s\n" "SESSION" "DATE" "SIZE" "DURATION" "ARGS"
    printf "%-20s %-12s %-8s %-20s %s\n" "-------" "----" "----" "--------" "----"
    
    for session in "${sessions[@]}"; do
        local basename_session=$(basename "$session")
        local meta_file="$(generate_metadata_filename "$session")"
        local size="N/A"
        local date="N/A"
        local duration="N/A"
        local args="N/A"
        
        # Get file size
        if [[ -f "$session" ]]; then
            local bytes=$(stat -f%z "$session" 2>/dev/null || stat -c%s "$session" 2>/dev/null || echo 0)
            size=$(bytes_to_size "$bytes")
        fi
        
        # Get metadata if available
        if [[ -f "$meta_file" ]]; then
            date=$(grep "session_start=" "$meta_file" 2>/dev/null | cut -d'"' -f2 | cut -d'T' -f1 || echo "N/A")
            local duration_sec=$(grep "duration_seconds=" "$meta_file" 2>/dev/null | cut -d'"' -f2 || echo "")
            if [[ -n "$duration_sec" ]]; then
                if (( duration_sec >= 3600 )); then
                    duration=$(printf "%dh%dm" $((duration_sec/3600)) $(((duration_sec%3600)/60)))
                elif (( duration_sec >= 60 )); then
                    duration=$(printf "%dm%ds" $((duration_sec/60)) $((duration_sec%60)))
                else
                    duration="${duration_sec}s"
                fi
            fi
            args=$(grep "claude_args=" "$meta_file" 2>/dev/null | cut -d'"' -f2 | head -c 30 || echo "")
            [[ ${#args} -eq 30 ]] && args="${args}..."
        fi
        
        printf "%-20s %-12s %-8s %-20s %s\n" "${basename_session:0:18}" "$date" "$size" "$duration" "$args"
    done
    
    echo
    log_info "Total sessions: ${#sessions[@]}"
}

# Search through sessions
search_sessions() {
    local search_term="$1"
    log_info "Searching for '$search_term' in recorded sessions..."
    echo
    
    local found_count=0
    local session_count=0
    
    while IFS= read -r -d $'\0' session; do
        ((session_count++))
        local basename_session=$(basename "$session")
        
        # Search in the session file
        if grep -l -i "$search_term" "$session" >/dev/null 2>&1; then
            ((found_count++))
            echo -e "${GREEN}=== $basename_session ===${NC}"
            
            # Show matching lines with context
            grep -i -n -C 2 --color=always "$search_term" "$session" | head -20
            echo
        fi
    done < <(find "$LOG_DIR" -name "*.log" -print0 2>/dev/null)
    
    if [[ $found_count -eq 0 ]]; then
        log_warning "No sessions found containing '$search_term'"
    else
        log_success "Found '$search_term' in $found_count out of $session_count sessions"
    fi
}

#==============================================================================
# v2.0 SUMMARIZATION FUNCTIONS
#==============================================================================

# Get summary prompt template
get_summary_prompt() {
    local session_id="$1"
    local session_date="$2"
    local duration="$3"
    local log_contents="$4"

    # Format date nicely
    local formatted_date=$(echo "$session_date" | cut -d'T' -f1-2 | tr 'T' ' ')

    # Truncate log if too long (safety measure)
    local log_length=${#log_contents}
    if (( log_length > 100000 )); then
        log_contents="${log_contents:0:100000}... [truncated]"
    fi

    # Build prompt
    cat << EOF
You are analyzing a Claude Code session log. Generate a concise summary following this EXACT format (use markdown):

# Session Summary
**Session ID**: ${session_id}
**Date**: ${formatted_date}
**Duration**: ${duration}
**Model**: claude-sonnet-4-5

## Overview
[2-3 sentences describing what was accomplished]

## Tasks Completed
- [Specific task with outcome]
- [Another task with outcome]

## Key Decisions & Insights
- [Important decision or learning]
- [Another insight]

## Files Modified
- \`/path/to/file\` - Brief description
- \`/another/file\` - Brief description

## Technologies/Topics
\`keyword1\`, \`keyword2\`, \`keyword3\`, ...

## Context for Future Reference
[Important context that would help understand this session later.
Include architectural decisions, gotchas, or warnings.]

## Follow-up Items
- [ ] Incomplete item or future enhancement
- [ ] Another follow-up

## Related Sessions
[If you can identify related past sessions from context, list them as:
claude_conversation.YYYYMMDD-HHMMSS]

---

IMPORTANT GUIDELINES:
- Keep summary concise but informative (aim for 200-400 words total)
- Focus on WHAT was done and WHY, not detailed HOW
- Extract key technical concepts for searchability
- Be specific about file paths and changes
- Identify clear action items from the session
- Use consistent formatting
- If session was very short or trivial, say so clearly

Session log follows:
---
${log_contents}
---
EOF
}

# Generate summary using Claude Code
generate_summary_claude_code() {
    local log_file="$1"
    local summary_file="$2"

    # Get session metadata
    local meta_file="${log_file%.log}.meta"
    local session_id=$(basename "$log_file" .log)
    local session_date=$(grep 'session_start=' "$meta_file" 2>/dev/null | cut -d'"' -f2 || echo "unknown")

    # Calculate duration
    local duration="unknown"
    local start_time=$(grep 'session_start=' "$meta_file" 2>/dev/null | cut -d'"' -f2)
    local end_time=$(grep 'session_end=' "$meta_file" 2>/dev/null | cut -d'"' -f2)

    if [[ -n "$start_time" ]] && [[ -n "$end_time" ]]; then
        # Calculate duration (cross-platform)
        local start_epoch=$(date_to_epoch "$start_time")
        local end_epoch=$(date_to_epoch "$end_time")

        if [[ "$start_epoch" != "0" ]] && [[ "$end_epoch" != "0" ]]; then
            local duration_seconds=$((end_epoch - start_epoch))
            if (( duration_seconds >= 3600 )); then
                duration=$(printf "%dh %dm" $((duration_seconds/3600)) $(((duration_seconds%3600)/60)))
            elif (( duration_seconds >= 60 )); then
                duration=$(printf "%dm %ds" $((duration_seconds/60)) $((duration_seconds%60)))
            else
                duration="${duration_seconds}s"
            fi
        fi
    fi

    # Read log contents
    local log_contents
    if [[ -f "$log_file" ]]; then
        log_contents=$(cat "$log_file")
    else
        log_error "Log file not found: $log_file"
        return 1
    fi

    # Generate prompt
    local prompt=$(get_summary_prompt "$session_id" "$session_date" "$duration" "$log_contents")

    # Call Claude Code
    verbose_log "Calling Claude Code to generate summary..."
    if echo "$prompt" | "$CLAUDE_CMD" --print > "$summary_file" 2>/dev/null; then
        return 0
    else
        return 1
    fi
}

# Generate summary with timeout protection
generate_summary_with_timeout() {
    local log_file="$1"
    local summary_file="$2"
    local timeout_seconds="${SUMMARY_TIMEOUT:-30}"

    # Start summarization in background
    generate_summary_claude_code "$log_file" "$summary_file" &
    local pid=$!

    # Wait with timeout and progress indicator
    local elapsed=0
    while kill -0 $pid 2>/dev/null; do
        sleep 1
        ((elapsed++))

        # Show progress every 5 seconds
        if (( elapsed % 5 == 0 )); then
            verbose_log "Generating summary... ${elapsed}s"
        fi

        # Check timeout
        if (( elapsed >= timeout_seconds )); then
            # Timeout reached - kill process
            kill -9 $pid 2>/dev/null
            wait $pid 2>/dev/null || true
            log_warning "Summary generation timed out after ${timeout_seconds}s"
            return 1
        fi
    done

    # Process completed - check result
    wait $pid
    local exit_code=$?

    if [[ $exit_code -eq 0 ]] && [[ -s "$summary_file" ]]; then
        # Success
        local file_size=$(stat -f%z "$summary_file" 2>/dev/null || stat -c%s "$summary_file" 2>/dev/null || echo 0)
        verbose_log "Summary created ($(bytes_to_size $file_size))"
        return 0
    else
        # Failed - clean up partial file
        [[ -f "$summary_file" ]] && rm -f "$summary_file"
        return 1
    fi
}

# Main summary generation function
generate_summary() {
    local log_file="$1"
    local summary_file="$2"

    # Check if summarization is enabled
    if [[ "$AUTO_SUMMARIZE" != "true" ]]; then
        return 0  # Skip, not an error
    fi

    # Check if log file exists
    if [[ ! -f "$log_file" ]] || [[ ! -r "$log_file" ]]; then
        log_error "Log file not found or not readable: $log_file"
        return 1
    fi

    # Check log size (skip if too large)
    local log_size=$(stat -f%z "$log_file" 2>/dev/null || stat -c%s "$log_file" 2>/dev/null || echo 0)
    if (( log_size > MAX_LOG_SIZE_FOR_SUMMARY )); then
        log_warning "Log file too large for summarization ($(bytes_to_size $log_size) > $(bytes_to_size $MAX_LOG_SIZE_FOR_SUMMARY))"
        log_info "Skipping summary generation"
        return 0  # Skip, not an error
    fi

    # Check minimum session length (if we can determine it)
    local meta_file="${log_file%.log}.meta"
    if [[ -f "$meta_file" ]]; then
        local start_time=$(grep 'session_start=' "$meta_file" 2>/dev/null | cut -d'"' -f2)
        local end_time=$(grep 'session_end=' "$meta_file" 2>/dev/null | cut -d'"' -f2)

        if [[ -n "$start_time" ]] && [[ -n "$end_time" ]]; then
            local start_epoch=$(date_to_epoch "$start_time")
            local end_epoch=$(date_to_epoch "$end_time")

            if [[ "$start_epoch" != "0" ]] && [[ "$end_epoch" != "0" ]]; then
                local duration=$((end_epoch - start_epoch))
                if (( duration < MIN_SESSION_LENGTH )); then
                    verbose_log "Session too short for summarization (${duration}s < ${MIN_SESSION_LENGTH}s)"
                    return 0  # Skip, not an error
                fi
            fi
        fi
    fi

    # Generate summary
    log_info "Generating session summary..."

    if generate_summary_with_timeout "$log_file" "$summary_file"; then
        log_success "Summary generated successfully"
        return 0
    else
        log_warning "Summary generation failed"
        log_info "You can try later with: claude-record --summarize-only"
        return 1
    fi
}

#==============================================================================
# END v2.0 SUMMARIZATION FUNCTIONS
#==============================================================================

#==============================================================================
# PHASE 2: KEYWORD INDEXING
#==============================================================================

# Extract keywords from summary and log files
extract_keywords() {
    local summary_file="$1"
    local log_file="$2"
    local keywords=()

    # Priority 1: Extract explicit tags from summary "## Technologies/Topics" section
    if [[ -f "$summary_file" ]]; then
        local in_topics=false
        while IFS= read -r line; do
            if [[ "$line" =~ ^##[[:space:]]*Technologies/Topics ]]; then
                in_topics=true
                continue
            fi

            if $in_topics && [[ -n "$line" ]] && [[ ! "$line" =~ ^## ]]; then
                # Parse comma-separated keywords, remove backticks
                IFS=',' read -ra tags <<< "$line"
                for tag in "${tags[@]}"; do
                    # Remove backticks, trim whitespace, convert to lowercase
                    tag=$(echo "$tag" | tr -d '`' | xargs | tr '[:upper:]' '[:lower:]')
                    if [[ -n "$tag" ]] && [[ "$tag" != "n/a" ]]; then
                        keywords+=("$tag")
                    fi
                done
                break
            fi
        done < "$summary_file"
    fi

    # Priority 2: Extract programming languages from file extensions in log
    if [[ -f "$log_file" ]]; then
        # Find file extensions (e.g., .py, .js, .go)
        local extensions=$(grep -oE '\.[a-zA-Z0-9]{2,4}' "$log_file" 2>/dev/null | sort -u || true)

        while IFS= read -r ext; do
            [[ -z "$ext" ]] && continue
            local lang=$(map_extension_to_language "$ext")
            if [[ -n "$lang" ]]; then
                keywords+=("$lang")
            fi
        done <<< "$extensions"
    fi

    # Priority 3: Search for common tech keywords in log
    local tech_keywords=(
        "docker" "kubernetes" "k8s" "aws" "gcp" "azure"
        "git" "api" "rest" "graphql" "database" "sql"
        "react" "vue" "angular" "node" "express" "flask"
        "django" "fastapi" "pytest" "jest" "testing"
        "authentication" "authorization" "oauth" "jwt"
        "nginx" "apache" "redis" "mongodb" "postgresql"
        "typescript" "javascript" "python" "java" "golang"
        "rust" "ruby" "php" "bash" "shell" "powershell"
    )

    if [[ -f "$log_file" ]]; then
        for keyword in "${tech_keywords[@]}"; do
            if grep -qi "$keyword" "$log_file" 2>/dev/null; then
                keywords+=("$keyword")
            fi
        done
    fi

    # Deduplicate, sort, and filter
    local unique_keywords=()
    if [[ ${#keywords[@]} -gt 0 ]]; then
        unique_keywords=($(printf '%s\n' "${keywords[@]}" | sort -u))
    fi

    # Remove stopwords
    local stopwords=("the" "and" "or" "in" "on" "at" "to" "for" "a")
    local filtered=()
    if [[ ${#unique_keywords[@]} -gt 0 ]]; then
        for kw in "${unique_keywords[@]}"; do
            local is_stopword=false
            for sw in "${stopwords[@]}"; do
                if [[ "$kw" == "$sw" ]]; then
                    is_stopword=true
                    break
                fi
            done
            if ! $is_stopword; then
                filtered+=("$kw")
            fi
        done
    fi

    # Return as JSON array
    if [[ ${#filtered[@]} -gt 0 ]]; then
        printf '%s\n' "${filtered[@]}" | jq -R . | jq -s .
    else
        echo "[]"
    fi
}

# Map file extension to programming language
map_extension_to_language() {
    local ext="$1"
    ext="${ext#.}"  # Remove leading dot
    ext=$(echo "$ext" | tr '[:upper:]' '[:lower:]')

    case "$ext" in
        py) echo "python" ;;
        js) echo "javascript" ;;
        ts) echo "typescript" ;;
        jsx) echo "react" ;;
        tsx) echo "react-typescript" ;;
        go) echo "golang" ;;
        rs) echo "rust" ;;
        java) echo "java" ;;
        c) echo "c" ;;
        cpp|cc) echo "cpp" ;;
        h) echo "c" ;;
        hpp) echo "cpp" ;;
        cs) echo "csharp" ;;
        rb) echo "ruby" ;;
        php) echo "php" ;;
        sh|bash) echo "bash" ;;
        zsh) echo "zsh" ;;
        ps1) echo "powershell" ;;
        sql) echo "sql" ;;
        html) echo "html" ;;
        css) echo "css" ;;
        scss) echo "scss" ;;
        json) echo "json" ;;
        yaml|yml) echo "yaml" ;;
        xml) echo "xml" ;;
        md) echo "markdown" ;;
        dockerfile) echo "docker" ;;
        tf) echo "terraform" ;;
        *) echo "" ;;
    esac
}

# Extract summary excerpt (first paragraph of Overview section)
extract_summary_excerpt() {
    local summary_file="$1"

    if [[ ! -f "$summary_file" ]]; then
        echo "N/A"
        return
    fi

    local in_overview=false
    local excerpt=""

    while IFS= read -r line; do
        if [[ "$line" =~ ^##[[:space:]]*Overview ]]; then
            in_overview=true
            continue
        fi

        if $in_overview; then
            # Skip empty lines
            if [[ -z "$line" ]]; then
                continue
            fi

            # Stop at next section
            if [[ "$line" =~ ^## ]]; then
                break
            fi

            # Get first non-empty line
            excerpt="$line"
            break
        fi
    done < "$summary_file"

    echo "${excerpt:-N/A}"
}

# Extract files modified from summary
extract_files_from_summary() {
    local summary_file="$1"

    if [[ ! -f "$summary_file" ]]; then
        echo "[]"
        return
    fi

    local in_files=false
    local files=()

    while IFS= read -r line; do
        if [[ "$line" =~ ^##[[:space:]]*Files[[:space:]]*Modified ]]; then
            in_files=true
            continue
        fi

        if $in_files; then
            # Stop at next section
            if [[ "$line" =~ ^## ]]; then
                break
            fi

            # Extract file paths from list items
            if [[ "$line" =~ ^-[[:space:]]*\`([^\`]+)\` ]] || [[ "$line" =~ ^-[[:space:]]*([^[:space:]]+) ]]; then
                local file="${BASH_REMATCH[1]}"
                if [[ -n "$file" ]] && [[ "$file" != "None" ]] && [[ "$file" != "N/A" ]]; then
                    files+=("$file")
                fi
            fi
        fi
    done < "$summary_file"

    # Return as JSON array
    if [[ ${#files[@]} -gt 0 ]]; then
        printf '%s\n' "${files[@]}" | jq -R . | jq -s .
    else
        echo "[]"
    fi
}

# Initialize session index structure
initialize_session_index() {
    cat <<EOF
{
  "version": "2.0",
  "last_updated": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
  "sessions": {}
}
EOF
}

# Initialize keyword index structure
initialize_keyword_index() {
    cat <<EOF
{
  "version": "2.0",
  "last_updated": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
  "total_sessions": 0,
  "keywords": {}
}
EOF
}

# Update session index with new session
update_session_index() {
    local session_id="$1"
    local date="$2"
    local duration="$3"
    local size="$4"
    local keywords_json="$5"
    local excerpt="$6"
    local files_json="$7"
    local working_dir="$8"

    local index_dir="$LOG_DIR/.claude-record"
    local index_file="$index_dir/session-index.json"

    # Ensure directory exists
    mkdir -p "$index_dir"

    # Load or create index
    local index
    if [[ -f "$index_file" ]]; then
        index=$(cat "$index_file")
    else
        index=$(initialize_session_index)
    fi

    # Build entry
    local entry=$(cat <<EOF
{
  "date": "$date",
  "duration_seconds": $duration,
  "size_bytes": $size,
  "has_summary": true,
  "keywords": $keywords_json,
  "summary_excerpt": $(echo "$excerpt" | jq -R .),
  "files_modified": $files_json,
  "working_directory": "$working_dir",
  "model": "claude-sonnet-4-5"
}
EOF
)

    # Update index with new entry
    index=$(echo "$index" | jq ".sessions[\"$session_id\"] = $entry | .last_updated = \"$(date -u +"%Y-%m-%dT%H:%M:%SZ")\"")

    # Write atomically
    echo "$index" > "$index_file.tmp"
    mv "$index_file.tmp" "$index_file"

    verbose_log "Session index updated for $session_id"
}

# Update keyword index with new session
update_keyword_index() {
    local session_id="$1"
    local keywords_json="$2"

    local index_dir="$LOG_DIR/.claude-record"
    local index_file="$index_dir/keyword-index.json"

    # Load or create index
    local index
    if [[ -f "$index_file" ]]; then
        index=$(cat "$index_file")
    else
        index=$(initialize_keyword_index)
    fi

    local current_time=$(date -u +"%Y-%m-%dT%H:%M:%SZ")

    # Process each keyword
    local keywords=()
    if [[ "$keywords_json" != "[]" ]]; then
        keywords=($(echo "$keywords_json" | jq -r '.[]'))
    fi

    if [[ ${#keywords[@]} -gt 0 ]]; then
        for keyword in "${keywords[@]}"; do
        # Check if keyword exists in index
        local has_keyword=$(echo "$index" | jq -r ".keywords[\"$keyword\"] != null")

        if [[ "$has_keyword" == "false" ]]; then
            # New keyword
            index=$(echo "$index" | jq ".keywords[\"$keyword\"] = {\"sessions\": [], \"frequency\": 0, \"last_used\": \"$current_time\"}")
        fi

        # Add session if not already present
        local has_session=$(echo "$index" | jq -r ".keywords[\"$keyword\"].sessions | index(\"$session_id\") != null")
        if [[ "$has_session" == "false" ]]; then
            index=$(echo "$index" | jq ".keywords[\"$keyword\"].sessions += [\"$session_id\"]")
        fi

        # Update frequency and last_used
        local freq=$(echo "$index" | jq ".keywords[\"$keyword\"].sessions | length")
        index=$(echo "$index" | jq ".keywords[\"$keyword\"].frequency = $freq | .keywords[\"$keyword\"].last_used = \"$current_time\"")
        done
    fi

    # Update global metadata
    local total=$(echo "$index" | jq '.keywords | to_entries | map(.value.sessions[]) | unique | length')
    index=$(echo "$index" | jq ".total_sessions = $total | .last_updated = \"$current_time\"")

    # Write atomically
    echo "$index" > "$index_file.tmp"
    mv "$index_file.tmp" "$index_file"

    verbose_log "Keyword index updated for $session_id"
}

# Main function to update both indexes
update_indexes() {
    local log_file="$1"
    local summary_file="$2"

    # Check if jq is available
    if ! command -v jq &> /dev/null; then
        verbose_log "jq not found, skipping index update (install with: brew install jq)"
        return 0
    fi

    # Extract session info
    local session_id=$(basename "$log_file" .log)
    local meta_file="${log_file%.log}.meta"

    # Get metadata
    local date=$(grep 'session_start=' "$meta_file" 2>/dev/null | cut -d'"' -f2 || echo "unknown")
    local working_dir=$(grep 'pwd=' "$meta_file" 2>/dev/null | cut -d'"' -f2 || echo "unknown")

    # Calculate duration
    local start_time=$(grep 'session_start=' "$meta_file" 2>/dev/null | cut -d'"' -f2)
    local end_time=$(grep 'session_end=' "$meta_file" 2>/dev/null | cut -d'"' -f2)
    local duration=0

    if [[ -n "$start_time" ]] && [[ -n "$end_time" ]]; then
        local start_epoch=$(date_to_epoch "$start_time")
        local end_epoch=$(date_to_epoch "$end_time")
        if [[ "$start_epoch" != "0" ]] && [[ "$end_epoch" != "0" ]]; then
            duration=$((end_epoch - start_epoch))
        fi
    fi

    # Get file size
    local size=$(stat -f%z "$log_file" 2>/dev/null || stat -c%s "$log_file" 2>/dev/null || echo 0)

    # Extract keywords and other info
    local keywords_json=$(extract_keywords "$summary_file" "$log_file")
    local excerpt=$(extract_summary_excerpt "$summary_file")
    local files_json=$(extract_files_from_summary "$summary_file")

    # Update both indexes
    update_session_index "$session_id" "$date" "$duration" "$size" "$keywords_json" "$excerpt" "$files_json" "$working_dir"
    update_keyword_index "$session_id" "$keywords_json"

    verbose_log "Indexes updated successfully"
    return 0
}

# Rebuild all indexes from existing summaries
rebuild_indexes() {
    log_info "Rebuilding indexes from existing summaries..."

    # Check if jq is available
    if ! command -v jq &> /dev/null; then
        log_error "jq is required for index rebuilding (install with: brew install jq)"
        return 1
    fi

    local index_dir="$LOG_DIR/.claude-record"
    mkdir -p "$index_dir"

    # Clear existing indexes
    initialize_session_index > "$index_dir/session-index.json"
    initialize_keyword_index > "$index_dir/keyword-index.json"

    local count=0

    # Process all summary files
    for summary_file in "$LOG_DIR"/*.summary; do
        [[ ! -f "$summary_file" ]] && continue

        local log_file="${summary_file%.summary}.log"
        if [[ -f "$log_file" ]]; then
            verbose_log "Processing: $(basename "$log_file")"
            update_indexes "$log_file" "$summary_file"
            ((count++))
        fi
    done

    log_success "Rebuilt indexes from $count sessions"
    log_info "Session index: $index_dir/session-index.json"
    log_info "Keyword index: $index_dir/keyword-index.json"

    return 0
}

#==============================================================================
# END PHASE 2: KEYWORD INDEXING
#==============================================================================

#==============================================================================
# PHASE 3: CONTEXT RETRIEVAL
#==============================================================================

# Get N most recent sessions from index
get_recent_sessions() {
    local num_recent="$1"
    local index_file="$LOG_DIR/.claude-record/session-index.json"

    if [[ ! -f "$index_file" ]]; then
        echo "[]"
        return
    fi

    # Check if jq is available
    if ! command -v jq &> /dev/null; then
        echo "[]"
        return
    fi

    # Extract session IDs sorted by date (newest first)
    local sessions=$(jq -r '.sessions | to_entries | sort_by(.value.date) | reverse | .[0:'$num_recent'] | .[].key' "$index_file" 2>/dev/null | jq -R . | jq -s . 2>/dev/null || echo "[]")

    echo "$sessions"
}

# Search for sessions by keywords
search_by_keywords() {
    local keywords_str="$1"
    local index_file="$LOG_DIR/.claude-record/keyword-index.json"

    if [[ ! -f "$index_file" ]] || [[ -z "$keywords_str" ]]; then
        echo "[]"
        return
    fi

    # Check if jq is available
    if ! command -v jq &> /dev/null; then
        echo "[]"
        return
    fi

    # Split keywords and search
    local session_counts="{}"
    IFS=' ' read -ra keywords <<< "$keywords_str"

    for keyword in "${keywords[@]}"; do
        keyword=$(echo "$keyword" | tr '[:upper:]' '[:lower:]')

        # Get sessions for this keyword
        local sessions=$(jq -r ".keywords[\"$keyword\"].sessions // []" "$index_file" 2>/dev/null || echo "[]")

        # Count occurrences
        if [[ "$sessions" != "[]" ]]; then
            while read -r session_id; do
                [[ -z "$session_id" ]] && continue
                local count=$(echo "$session_counts" | jq -r ".[\"$session_id\"] // 0" 2>/dev/null || echo "0")
                ((count++))
                session_counts=$(echo "$session_counts" | jq ". + {\"$session_id\": $count}" 2>/dev/null)
            done < <(echo "$sessions" | jq -r '.[]' 2>/dev/null)
        fi
    done

    # Sort by count and return session IDs
    local sorted=$(echo "$session_counts" | jq -r 'to_entries | sort_by(.value) | reverse | .[].key' 2>/dev/null | jq -R . | jq -s . 2>/dev/null || echo "[]")

    echo "$sorted"
}

# Get sessions that modified files in current directory
get_sessions_by_directory() {
    local directory="$1"
    local index_file="$LOG_DIR/.claude-record/session-index.json"

    if [[ ! -f "$index_file" ]]; then
        echo "[]"
        return
    fi

    # Check if jq is available
    if ! command -v jq &> /dev/null; then
        echo "[]"
        return
    fi

    # Find sessions with files in this directory
    local sessions=$(jq -r --arg dir "$directory" '
        .sessions | to_entries |
        map(select(.value.files_modified | any(startswith($dir)))) |
        sort_by(.value.date) | reverse |
        .[].key
    ' "$index_file" 2>/dev/null | jq -R . | jq -s . 2>/dev/null || echo "[]")

    echo "$sessions"
}

# Calculate time ago from ISO date
calculate_time_ago() {
    local date_str="$1"

    # Calculate epoch using cross-platform function
    local session_epoch=$(date_to_epoch "$date_str")
    local now_epoch=$(date "+%s")

    if [[ "$session_epoch" == "0" ]]; then
        echo "unknown"
        return
    fi

    local diff=$((now_epoch - session_epoch))

    if (( diff < 60 )); then
        echo "${diff}s ago"
    elif (( diff < 3600 )); then
        echo "$((diff / 60))m ago"
    elif (( diff < 86400 )); then
        echo "$((diff / 3600))h ago"
    elif (( diff < 604800 )); then
        echo "$((diff / 86400))d ago"
    else
        echo "$((diff / 604800))w ago"
    fi
}

# Display context to user
display_context_to_user() {
    local sessions_json="$1"

    # Check if empty
    local count=$(echo "$sessions_json" | jq 'length' 2>/dev/null || echo "0")
    if [[ "$count" == "0" ]]; then
        return
    fi

    local index_file="$LOG_DIR/.claude-record/session-index.json"
    if [[ ! -f "$index_file" ]]; then
        return
    fi

    # Print header
    echo >&2
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}" >&2
    echo -e "${BLUE}ðŸ“š Relevant Past Sessions Found:${NC}" >&2
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}" >&2
    echo >&2

    local num=1
    while read -r session_id; do
        [[ -z "$session_id" ]] && continue

        # Get session data
        local data=$(jq -r ".sessions[\"$session_id\"]" "$index_file" 2>/dev/null)
        [[ "$data" == "null" ]] && continue

        # Extract fields
        local date=$(echo "$data" | jq -r '.date' 2>/dev/null)
        local excerpt=$(echo "$data" | jq -r '.summary_excerpt' 2>/dev/null | cut -c 1-80)
        local keywords=$(echo "$data" | jq -r '.keywords[0:5] | join(", ")' 2>/dev/null)
        local files=$(echo "$data" | jq -r '.files_modified[0:3] | join(", ")' 2>/dev/null)
        local file_count=$(echo "$data" | jq -r '.files_modified | length' 2>/dev/null || echo "0")

        # Calculate time ago
        local time_ago=$(calculate_time_ago "$date")

        # Format date
        local formatted_date=$(echo "${date:0:10} ${date:11:5}")

        # Print session info
        echo -e "${GREEN}[$num]${NC} ${formatted_date} ${YELLOW}(${time_ago})${NC}" >&2
        echo -e "    ${excerpt}" >&2
        if [[ -n "$keywords" ]] && [[ "$keywords" != "" ]]; then
            echo -e "    ${PURPLE}Tags:${NC} ${keywords}" >&2
        fi
        if [[ -n "$files" ]] && [[ "$files" != "" ]]; then
            if (( file_count > 3 )); then
                echo -e "    ${PURPLE}Files:${NC} ${files}, ..." >&2
            else
                echo -e "    ${PURPLE}Files:${NC} ${files}" >&2
            fi
        fi
        echo >&2

        ((num++))
    done < <(echo "$sessions_json" | jq -r '.[]' 2>/dev/null)

    # Print footer
    echo -e "${BLUE}ðŸ’¡ These summaries provide context for this session.${NC}" >&2
    echo -e "${CYAN}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${NC}" >&2
    echo >&2
}

# Main context retrieval function
retrieve_context() {
    # Skip if context disabled
    if [[ "$SHOW_CONTEXT" != "true" ]]; then
        return 0
    fi

    # Check if jq is available
    if ! command -v jq &> /dev/null; then
        verbose_log "jq not found, skipping context retrieval"
        return 0
    fi

    # Check if index exists
    local index_file="$LOG_DIR/.claude-record/session-index.json"
    if [[ ! -f "$index_file" ]]; then
        verbose_log "No session index found, skipping context retrieval"
        return 0
    fi

    local session_ids="[]"

    # Choose retrieval strategy based on mode
    case "$CONTEXT_MODE" in
        recent)
            session_ids=$(get_recent_sessions "$NUM_CONTEXT_SESSIONS")
            ;;

        smart)
            # Combine recent + directory-based
            local recent=$(get_recent_sessions 2)
            local dir_based=$(get_sessions_by_directory "$PWD")

            # Merge and deduplicate
            session_ids=$(echo "$recent $dir_based" | jq -s 'add | unique | .[0:'$NUM_CONTEXT_SESSIONS']' 2>/dev/null || echo "[]")
            ;;

        keywords)
            if [[ -n "$CONTEXT_KEYWORDS" ]]; then
                session_ids=$(search_by_keywords "$CONTEXT_KEYWORDS")
                # Limit to NUM_CONTEXT_SESSIONS
                session_ids=$(echo "$session_ids" | jq '.[0:'$NUM_CONTEXT_SESSIONS']' 2>/dev/null || echo "[]")
            else
                # Fallback to recent if no keywords provided
                session_ids=$(get_recent_sessions "$NUM_CONTEXT_SESSIONS")
            fi
            ;;

        *)
            session_ids=$(get_recent_sessions 3)
            ;;
    esac

    # Display context to user
    display_context_to_user "$session_ids"

    return 0
}

#==============================================================================
# END PHASE 3: CONTEXT RETRIEVAL
#==============================================================================

# Check if Claude command exists
check_claude_command() {
    if ! command -v "$CLAUDE_CMD" &> /dev/null; then
        log_error "Claude command '$CLAUDE_CMD' not found in PATH"
        log_error "Please install Claude Code or set CLAUDE_CMD environment variable"
        exit 1
    fi
}

# Parse command line arguments
parse_args() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            -h|--help)
                show_help
                exit 0
                ;;
            -d|--directory)
                LOG_DIR="$2"
                shift 2
                ;;
            -f|--filename)
                CUSTOM_FILENAME="$2"
                shift 2
                ;;
            -s|--max-size)
                MAX_SIZE="$2"
                shift 2
                ;;
            -m|--max-sessions)
                MAX_SESSIONS="$2"
                shift 2
                ;;
            -v|--verbose)
                VERBOSE=true
                shift
                ;;
            --dry-run)
                DRY_RUN=true
                shift
                ;;
            --cleanup)
                CLEANUP_ONLY=true
                shift
                ;;
            --list)
                LIST_SESSIONS=true
                shift
                ;;
            --search)
                SEARCH_TERM="$2"
                shift 2
                ;;
            --no-auto-cleanup)
                AUTO_CLEANUP=false
                shift
                ;;
            --no-summarize)
                AUTO_SUMMARIZE=false
                shift
                ;;
            --summarize-only)
                SUMMARIZE_ONLY=true
                shift
                ;;
            --rebuild-index)
                REBUILD_INDEX=true
                shift
                ;;
            --no-context)
                SHOW_CONTEXT=false
                shift
                ;;
            --context)
                CONTEXT_MODE="$2"
                shift 2
                ;;
            --context-keywords)
                CONTEXT_KEYWORDS="$2"
                CONTEXT_MODE="keywords"
                shift 2
                ;;
            --version)
                echo "$SCRIPT_NAME version $SCRIPT_VERSION"
                exit 0
                ;;
            --)
                shift
                break
                ;;
            -*)
                log_error "Unknown option: $1"
                echo "Use --help for usage information"
                exit 1
                ;;
            *)
                break
                ;;
        esac
    done
    
    # Remaining arguments are passed to Claude
    CLAUDE_ARGS=("$@")
}

# Validate arguments
validate_args() {
    # Validate max size format
    if ! [[ "$MAX_SIZE" =~ ^[0-9]+[KMGT]?B?$ ]]; then
        log_error "Invalid size format: $MAX_SIZE"
        log_error "Use formats like: 50M, 1G, 512K, 2048"
        exit 1
    fi
    
    # Validate max sessions is a number
    if ! [[ "$MAX_SESSIONS" =~ ^[0-9]+$ ]]; then
        log_error "Invalid max sessions: $MAX_SESSIONS (must be a number)"
        exit 1
    fi
    
    # Expand LOG_DIR
    LOG_DIR="${LOG_DIR/#\~/$HOME}"
    
    # Override with environment variables if set
    [[ -n "${CLAUDE_RECORD_DIR:-}" ]] && LOG_DIR="$CLAUDE_RECORD_DIR"
    [[ -n "${CLAUDE_RECORD_MAX_SIZE:-}" ]] && MAX_SIZE="$CLAUDE_RECORD_MAX_SIZE"
    [[ -n "${CLAUDE_CMD:-}" ]] && CLAUDE_CMD="$CLAUDE_CMD"
}

# Main execution
main() {
    # Parse and validate arguments
    parse_args "$@"
    validate_args
    
    # Handle special modes
    if [[ "$LIST_SESSIONS" == "true" ]]; then
        setup_log_directory
        list_sessions
        exit 0
    fi
    
    if [[ -n "$SEARCH_TERM" ]]; then
        setup_log_directory
        search_sessions "$SEARCH_TERM"
        exit 0
    fi
    
    if [[ "$CLEANUP_ONLY" == "true" ]]; then
        setup_log_directory
        cleanup_old_sessions
        exit 0
    fi

    # v2.0: Handle --summarize-only mode
    if [[ "$SUMMARIZE_ONLY" == "true" ]]; then
        setup_log_directory

        # Find most recent log file
        local latest_log=$(find "$LOG_DIR" -name "*.log" -type f 2>/dev/null | sort -r | head -1)

        if [[ -z "$latest_log" ]]; then
            log_error "No session logs found in $LOG_DIR"
            exit 1
        fi

        local summary_file="${latest_log%.log}.summary"

        # Check if summary already exists
        if [[ -f "$summary_file" ]]; then
            log_warning "Summary already exists: $(basename "$summary_file")"
            read -p "Regenerate? (y/N) " -n 1 -r
            echo
            if [[ ! $REPLY =~ ^[Yy]$ ]]; then
                log_info "Aborted"
                exit 0
            fi
        fi

        log_info "Generating summary for: $(basename "$latest_log")"

        if generate_summary "$latest_log" "$summary_file"; then
            # Update metadata
            local meta_file="${latest_log%.log}.meta"
            if [[ -f "$meta_file" ]] && ! grep -q "has_summary=" "$meta_file"; then
                echo 'has_summary="true"' >> "$meta_file"
            fi

            log_success "Summary saved to: $(basename "$summary_file")"

            # Update indexes
            update_indexes "$latest_log" "$summary_file" || verbose_log "Index update failed (non-fatal)"

            exit 0
        else
            log_error "Failed to generate summary"
            exit 1
        fi
    fi

    # v2.0: Handle --rebuild-index mode
    if [[ "$REBUILD_INDEX" == "true" ]]; then
        setup_log_directory
        rebuild_indexes
        exit $?
    fi

    # Check for Claude command
    check_claude_command
    
    # Setup environment
    setup_log_directory
    
    # Auto-cleanup if enabled
    if [[ "$AUTO_CLEANUP" == "true" ]]; then
        cleanup_old_sessions
    fi

    # v2.0 Phase 3: Retrieve context from past sessions
    retrieve_context

    # Generate log file
    local log_file
    log_file=$(generate_filename)
    local start_time=$(date -Iseconds)
    
    verbose_log "Session will be recorded to: $(basename "$log_file")"
    verbose_log "Maximum file size: $MAX_SIZE"
    verbose_log "Claude command: $CLAUDE_CMD ${CLAUDE_ARGS[*]:-}"
    
    if [[ "$DRY_RUN" == "true" ]]; then
        log_info "DRY RUN - Would execute: $CLAUDE_CMD ${CLAUDE_ARGS[*]:-}"
        log_info "Would record to: $log_file"
        exit 0
    fi
    
    # Create metadata
    create_metadata "$log_file" "$start_time" "${CLAUDE_ARGS[@]:-}"
    
    log_info "Starting Claude session recording..."
    log_info "Session file: $(basename "$log_file")"
    log_info "Press Ctrl+C to end session"
    echo
    
    # Start recording session
    local exit_code=0
    
    # Create header for log file
    {
        echo "=== Claude Session Started at $start_time ==="
        echo "Command: $CLAUDE_CMD ${CLAUDE_ARGS[*]:-}"
        echo "Directory: $(pwd)"
        echo "User: $(whoami)@$(hostname)"
        echo "=== Session Log ==="
        echo
    } > "$log_file"
    
    # Use script -B to record both input and output, then filter
    local raw_log_file="${log_file}.raw"
    
    # Force interactive mode if no arguments provided
    if [[ ${#CLAUDE_ARGS[@]:-0} -eq 0 ]]; then
        # No arguments - force interactive mode by not passing --print
        script -B "$raw_log_file" -a -c "$CLAUDE_CMD" || exit_code=$?
    else
        # Arguments provided - pass them through
        script -B "$raw_log_file" -a -c "$CLAUDE_CMD ${CLAUDE_ARGS[*]}" || exit_code=$?
    fi
    
    # Filter out repetitive Claude UI sequences to reduce log size
    verbose_log "Filtering repetitive UI sequences from log..."
    filter_claude_ui_sequences "$raw_log_file" "$log_file"
    
    # Remove raw log file
    rm -f "$raw_log_file"
    
    # Add footer to log file
    {
        echo
        echo "=== Session Ended at $(date -Iseconds) ==="
    } >> "$log_file"
    
    # Update metadata
    local end_time=$(date -Iseconds)
    local final_size=$(stat -f%z "$log_file" 2>/dev/null || stat -c%s "$log_file" 2>/dev/null || echo 0)
    update_metadata "$log_file" "$end_time" "$final_size"

    echo
    log_success "Session recorded to: $(basename "$log_file")"
    log_success "Session size: $(bytes_to_size "$final_size")"

    # v2.0: Generate summary
    if [[ "$AUTO_SUMMARIZE" == "true" ]]; then
        local summary_file="${log_file%.log}.summary"

        if generate_summary "$log_file" "$summary_file"; then
            # Update metadata to indicate summary exists
            local meta_file="${log_file%.log}.meta"
            echo 'has_summary="true"' >> "$meta_file"

            log_success "Summary saved to: $(basename "$summary_file")"

            # v2.0 Phase 2: Update indexes
            update_indexes "$log_file" "$summary_file" || verbose_log "Index update failed (non-fatal)"
        else
            # Non-fatal error - session is still recorded
            verbose_log "Session recorded without summary"
        fi
        echo
    fi

    # Check if rotation is needed
    if check_file_size "$log_file"; then
        log_warning "Session file exceeds size limit, consider using --max-size option"
    fi

    exit $exit_code
}

# Handle signals gracefully
trap 'echo; log_info "Session interrupted by user"; exit 130' INT TERM

# Run main function
main "$@"